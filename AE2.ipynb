{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE\n",
    "## Adrian Zaręba | 320672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "# Algorytm Genetyczny\n",
    "\n",
    "### Wprowadzenie\n",
    "\n",
    "Algorytmy genetyczne to metoda optymalizacji inspirowana procesami ewolucyjnymi zachodzącymi w przyrodzie. Są one wykorzystywane do rozwiązywania problemów, które mogą być trudne lub wręcz niemożliwe do rozwiązania za pomocą tradycyjnych metod.\n",
    "\n",
    "### Podstawowe Elementy Algorytmu Genetycznego\n",
    "\n",
    "#### Chromosom\n",
    "\n",
    "Chromosom to reprezentacja jednego rozwiązania problemu. W kontekście algorytmów genetycznych może to być ciąg bitów, liczby rzeczywiste, permutacje itp. W naszym przykładzie jest to zestaw wag sieci neuronowej.\n",
    "\n",
    "#### Populacja\n",
    "\n",
    "Populacja to zbiór możliwych rozwiązań problemu, które są oceniane i ewoluowane w trakcie działania algorytmu. Każde rozwiązanie nazywane jest osobnikiem.\n",
    "\n",
    "#### Funkcja Fitness\n",
    "\n",
    "Funkcja oceny, zwana również funkcją fitness, mierzy jakość poszczególnych osobników w populacji. Celem algorytmu jest maksymalizacja lub minimalizacja tej funkcji. W naszym przypadku jest to funkcja błędu średniokwadratowego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zareb\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y.reshape(-1, 1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "### 1. Funkcje Aktywacji\n",
    "\n",
    "- `sigmoid(x)`: Funkcja sigmoidalna przekształca wartości wejściowe w zakres (0, 1), co jest użyteczne w problemach klasyfikacyjnych.\n",
    "- `relu(x)`: Funkcja ReLU zwraca 0 dla wartości ujemnych i samo x dla wartości dodatnich, co pomaga w unikaniu problemu zanikania gradientu.\n",
    "- `tanh(x)`: Funkcja tangens hiperboliczny przekształca wartości wejściowe w zakres (-1, 1), co jest użyteczne w różnych zastosowaniach sieci neuronowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "### 2. Inicjalizacja Populacji\n",
    "\n",
    "- `initialize_population(input_size, hidden_layers, output_size, population_size)`: Tworzy początkową populację losowych sieci neuronowych. Każda sieć neuronowa ma określoną liczbę warstw i neurony w każdej warstwie są inicjalizowane losowymi wagami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_population(input_size, hidden_layers, output_size, population_size):\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        individual = []\n",
    "        layer_sizes = [input_size] + hidden_layers + [output_size]\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            weights = np.random.randn(layer_sizes[i], layer_sizes[i + 1])\n",
    "            individual.append(weights)\n",
    "        population.append(individual)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "### 3. Przekazywanie Sygnałów przez Sieć (Forward Pass)\n",
    "\n",
    "- `forward_pass(individual, X, activation_func)`: Przetwarza dane wejściowe przez sieć neuronową, używając wybranej funkcji aktywacji, aż do uzyskania wyników na wyjściu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(individual, X, activation_func):\n",
    "    layer_output = X\n",
    "    for weights in individual:\n",
    "        layer_output = activation_func(np.dot(layer_output, weights))\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "### 4. Funkcja Fitness\n",
    "\n",
    "- `fitness(individual, X_train, y_train, activation_func)`: Mierzy jakość osobników na podstawie średniego błędu kwadratowego między przewidywanymi a rzeczywistymi wartościami. Im mniejszy błąd, tym lepszy osobnik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(individual, X_train, y_train, activation_func):\n",
    "    predictions = forward_pass(individual, X_train, activation_func)\n",
    "    error = np.mean((y_train - predictions) ** 2)\n",
    "    return -error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "### 5. Selekcja\n",
    "\n",
    "- `select(population, fitnesses)`: Wybiera najlepszych osobników z populacji do dalszej reprodukcji. Osobniki z najlepszymi wynikami fitness mają większe szanse na wybór, co zapewnia, że korzystne cechy są przekazywane potomkom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(population, fitnesses):\n",
    "    sorted_indices = np.argsort(fitnesses)\n",
    "    top_half = sorted_indices[len(sorted_indices) // 2:]\n",
    "    selected_indices = np.random.choice(top_half, size=len(population), replace=True)\n",
    "    return [population[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "### 6. Krzyżowanie (Crossover)\n",
    "\n",
    "- `crossover(parent1, parent2)`: Łączy dwa chromosomy rodzicielskie, tworząc nowe chromosomy potomne. Proces ten polega na wymianie części wag między dwa rodzicami, co prowadzi do powstania nowych kombinacji wag w potomkach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    child1, child2 = [], []\n",
    "    for w1, w2 in zip(parent1, parent2):\n",
    "        point = random.randint(1, w1.size - 1)\n",
    "        w1_flat, w2_flat = w1.flatten(), w2.flatten()\n",
    "        c1_flat = np.concatenate((w1_flat[:point], w2_flat[point:]))\n",
    "        c2_flat = np.concatenate((w2_flat[:point], w1_flat[point:]))\n",
    "        child1.append(c1_flat.reshape(w1.shape))\n",
    "        child2.append(c2_flat.reshape(w2.shape))\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "### 7. Mutacja\n",
    "\n",
    "- `mutate(individual, mutation_rate)`: Wprowadza losowe zmiany do wag osobników, co jest ważne, aby zachować różnorodność genetyczną populacji i zapobiegać zbieżności do lokalnych minimów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(individual, mutation_rate=0.01):\n",
    "    for weights in individual:\n",
    "        if random.random() < mutation_rate:\n",
    "            mutation = np.random.randn(*weights.shape) * mutation_rate\n",
    "            weights += mutation\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "### 8. Algorytm Genetyczny\n",
    "\n",
    "- `genetic_algorithm(input_size, hidden_layers, output_size, population_size, generations, activation_func)`: Łączy wszystkie kroki w jednym algorytmie genetycznym, który iteracyjnie poprawia populację sieci neuronowych. Algorytm działa przez określoną liczbę generacji, w każdej z nich przeprowadzając selekcję, krzyżowanie i mutację."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(input_size, hidden_layers, output_size, population_size, generations, activation_func):\n",
    "    population = initialize_population(input_size, hidden_layers, output_size, population_size)\n",
    "    for generation in range(generations):\n",
    "        fitnesses = np.array([fitness(ind, X_train, y_train, activation_func) for ind in population])\n",
    "        population = select(population, fitnesses)\n",
    "        next_population = []\n",
    "        for i in range(population_size // 2):\n",
    "            parent1, parent2 = population[2*i], population[2*i + 1]\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            next_population.append(mutate(child1))\n",
    "            next_population.append(mutate(child2))\n",
    "        population = next_population\n",
    "        if generation % 10 == 0:\n",
    "            best_fitness = max(fitnesses)\n",
    "            print(f'Generation {generation}: Best Fitness = {1+best_fitness:.4f}', end='\\r')\n",
    "    \n",
    "    best_individual = population[np.argmax([fitness(ind, X_train, y_train, activation_func) for ind in population])]\n",
    "    return best_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "## Zastosowanie na Zbiorze Danych Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 790: Best Fitness = 0.8906\n",
      "Accuracy on test set: 80.00%\n"
     ]
    }
   ],
   "source": [
    "# Pobieranie danych do odpowiedniego formatu\n",
    "scaler = StandardScaler()\n",
    "X_train_IRIS = scaler.fit_transform(X_train)\n",
    "X_test_IRIS = scaler.transform(X_test)\n",
    "\n",
    "# Definiowanie architekruty \n",
    "input_size = X_train_IRIS.shape[1]\n",
    "hidden_layers = [5, 5]\n",
    "output_size = y_train.shape[1]\n",
    "population_size = 400\n",
    "generations = 800\n",
    "activation_func = sigmoid\n",
    "\n",
    "# Algorytm genetyczny\n",
    "best_individual = genetic_algorithm(input_size, hidden_layers, output_size, population_size, generations, activation_func)\n",
    "\n",
    "predictions = forward_pass(best_individual, X_test_IRIS, activation_func)\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "\n",
    "print(f'\\nAccuracy on test set: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  h1, h2, h3, h4 {\n",
    "    color: #458dc8;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "## Podsumowanie\n",
    "\n",
    "W trakcie działania algorytmu genetycznego na zbiorze danych Iris, algorytm iteracyjnie poprawiał populację sieci neuronowych, aby znaleźć optymalne wagi, które minimalizują błąd predykcji. Proces ten obejmował inicjalizację populacji, ocenę osobników za pomocą funkcji fitness, selekcję najlepszych osobników, krzyżowanie w celu wymiany informacji genetycznej oraz mutację dla zachowania różnorodności.\n",
    "\n",
    "### Dlaczego Algorytmy Genetyczne Działają w Sieciach Neuronowych (MLP)\n",
    "\n",
    "W sieciach neuronowych typu MLP proces uczenia polega na dostosowywaniu wag, aby minimalizować różnicę między przewidywaniami sieci a rzeczywistymi wynikami. Tradycyjne metody, takie jak algorytm wstecznej propagacji (backpropagation), mogą być skuteczne, ale czasami zmagają się z problemami, takimi jak utkwienie w lokalnych minimach. Algorytmy genetyczne, dzięki ich globalnemu podejściu do przeszukiwania przestrzeni rozwiązań, mogą uniknąć takich pułapek i znaleźć bardziej optymalne rozwiązania.\n",
    "\n",
    "Algorytmy genetyczne działają dobrze w MLP, ponieważ:\n",
    "\n",
    "1. **Różnorodność Rozwiązań**: Przez inicjalizację populacji losowych wag i stosowanie krzyżowania oraz mutacji, algorytmy genetyczne mogą eksplorować szeroki zakres możliwych rozwiązań.\n",
    "2. **Globalne Poszukiwanie**: Algorytmy te są mniej podatne na utkwienie w lokalnych minimach w porównaniu do algorytmów gradientowych, ponieważ przeszukują przestrzeń rozwiązań bardziej globalnie.\n",
    "3. **Eliminacja Złożonych Obliczeń Gradientowych**: Algorytmy genetyczne nie wymagają obliczania gradientów, co może być zaletą w przypadku skomplikowanych i niegładkich funkcji kosztu.\n",
    "\n",
    "### Zastosowania Algorytmów Genetycznych\n",
    "\n",
    "Oprócz optymalizacji wag w sieciach neuronowych, algorytmy genetyczne mają szerokie zastosowania w różnych dziedzinach:\n",
    "\n",
    "- **Inżynieria**: Optymalizacja konstrukcji, projektowanie układów mechanicznych i elektronicznych.\n",
    "- **Ekonomia i Finanse**: Optymalizacja portfela inwestycyjnego, prognozowanie ekonomiczne.\n",
    "- **Biologia i Medycyna**: Modelowanie procesów biologicznych, analiza sekwencji DNA, projektowanie leków.\n",
    "- **Informatyka**: Rozwiązywanie problemów NP-trudnych, takich jak problem komiwojażera, projektowanie układów cyfrowych.\n",
    "- **Robotyka**: Optymalizacja trajektorii ruchu, projektowanie systemów kontrolnych.\n",
    "\n",
    "Algorytmy genetyczne są wszechstronnym narzędziem, które może być dostosowane do szerokiego zakresu problemów optymalizacyjnych, dzięki swojej zdolności do eksploracji i eksploatacji dużych przestrzeni rozwiązań. W połączeniu z innymi metodami uczenia maszynowego i sztucznej inteligencji, mogą prowadzić do bardziej efektywnych i innowacyjnych rozwiązań w wielu dziedzinach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
